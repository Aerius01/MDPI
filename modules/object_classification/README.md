# Object Classification Module

## Abstract

The Object Classification module is the final and most critical step in the MDPI image processing pipeline. It follows the `object_detection` module and its purpose is to take the vignettes (small, cropped images of detected objects) and assign a class label to each one. This is achieved using a pre-trained Convolutional Neural Network (CNN). The module processes vignettes in batches, runs them through the CNN for inference, and outputs the classification results. In addition to the primary class label, it also calculates several uncertainty metrics for each prediction, providing insight into the model's confidence. The final output is a comprehensive CSV file that merges the classification results with the object data from the detection phase.

## Prerequisites

To run this module, you must have already processed your data through the `object_detection` module. This classification step requires two key outputs from the detection phase:
1.  The directory of vignette images.
2.  The `object_data.csv` file containing feature data for each vignette.

## How it Works

The classification process is orchestrated through several interconnected components:

1.  **Data Ingestion and Validation:** The module begins by locating and loading the vignettes from the specified input directory. It also requires the `object_data.csv` file generated by the detection module, which it uses to link classifications back to the original object features. The paths to the pre-trained model and output directory are also validated.

2.  **Image Preprocessing:** Before being fed into the CNN, all vignettes undergo a standardized preprocessing routine. This involves resizing each image to the model's expected input size (e.g., 50x50 pixels) and normalizing the pixel values.

3.  **Model Loading and Inference:** The module loads the pre-trained TensorFlow model from the specified checkpoint files. The inference engine then processes the preprocessed vignettes in batches for efficiency. For each vignette, the model outputs a vector of raw prediction scores (logits) for each possible class.

4.  **Prediction Post-processing:** The raw logits from the model are converted into probabilities using a softmax function. The class with the highest probability is chosen as the predicted label for the vignette.

5.  **Uncertainty Calculation:** To gauge the model's confidence, several uncertainty metrics are calculated from the probability distribution for each prediction:
    *   **Least Confidence:** Measures the difference between 1 and the highest prediction probability.
    *   **Margin Sampling:** Calculates the difference between the two highest prediction probabilities.
    *   **Entropy:** Measures the overall uncertainty in the probability distribution.

6.  **Data Aggregation and Output:** The classification results (predicted label, probabilities, and uncertainty metrics) are compiled into a new DataFrame. This DataFrame is then merged with the original `object_data.csv` using the vignette filename as a key. The final, enriched dataset is saved as a new CSV file, overwriting the old one. A pickle file containing the raw classification results is also saved for potential use with other tools like the LabelChecker.

## How to Use

The Object Classification module is executed from the command line.

### CLI Structure

The basic command to run the module is:

```bash
python3 -m modules.object_classification -i <input_directory> -m <model_directory> -o <output_directory>
```

The `<input_directory>` should point to the directory containing the vignette images, typically structured as: `<...>/<project_name>/<YYYYMMDD>/<cycle>/<location>/vignettes`.

### Example

This command classifies vignettes from the specified directory using a model located at `./model` and saves the results to the default `./output` directory.

```bash
python3 -m modules.object_classification -i <...>/Project-Example/20230424/day/E07-01/vignettes -m ./model
```

## Input Argument Formats

-   `-i, --input` (Required): Path to the directory containing the vignette images. The path structure `<...>/<project_name>/<YYYYMMDD>/<cycle>/<location>/<any_directory_name>` is expected for metadata parsing.
-   `-m, --model` (Required): Path to the directory containing the trained model files (specifically, the `model.ckpt` checkpoint files).
-   `-o, --output` (Optional): The root directory for the output files. Defaults to `./output`.
-   `--batch-size` (Optional): The number of vignettes to process in each batch. Defaults to 32.
-   `--input-size` (Optional): The height and width (in pixels) to which vignettes are resized. Must match the input size the CNN was trained on. Defaults to 50.
-   `--input-depth` (Optional): The number of channels for the input images. Defaults to 1 (grayscale).

## Module Outputs

-   **Updated Object Data CSV:** The module overwrites the `object_data.csv` file (located one level above the vignettes directory) with a new version that includes the classification results. New columns for `prediction` and `label` are added.
-   **Classification Pickle File:** A file named `object_data.pkl` is saved in the same directory as the CSV. It contains a serialized dictionary with the raw classification results, including probabilities and uncertainty metrics, which can be used by the class viewer (see `class_viewer.py`).

## Pipeline Completion

This module marks the end of the standard MDPI image processing pipeline. The final `object_data.csv` file contains the complete dataset, including object features, depth information, and class predictions.

## Constants, Concerns, and Limitations

### Constants

-   **`CLASSIFICATION_CATEGORIES`:** A list of class names that the model can predict (e.g., `['cladocera', 'copepod', 'junk', 'rotifer']`). This list must match the classes the model was trained on.
-   **Model Input Dimensions:** `CLASSIFICATION_INPUT_SIZE` and `CLASSIFICATION_INPUT_DEPTH` define the expected dimensions of the input vignettes for the CNN. These must align with the architecture of the loaded model.

### Concerns and Limitations

-   **Model Dependency:** The module's accuracy is entirely dependent on the quality and suitability of the pre-trained CNN model. A model trained on one type of data may not generalize well to another.
-   **TensorFlow 1.x:** The current implementation uses TensorFlow 1.x syntax. This is an older version of the framework, and the code may require significant updates to be compatible with modern TensorFlow 2.x environments.
-   **Fixed Class Set:** The set of possible classification categories is hardcoded. To classify new types of objects, the model must be retrained, and the `CLASSIFICATION_CATEGORIES` constant in the code must be updated.
-   **"Label" vs. "Prediction":** The module saves the model's prediction under two columns, `prediction` and `label`. This is a legacy feature and might be confusing, as the `label` in this context is not a ground-truth value but simply a copy of the model's output.
